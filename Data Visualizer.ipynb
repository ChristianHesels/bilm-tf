{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_file = h5py.File(\"elmo_embeddings.hdf5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85358\n"
     ]
    }
   ],
   "source": [
    "print(len(lm_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "vector_dict = defaultdict(list)\n",
    "\n",
    "with open(\"/home/chris/Dev/uni/master/props-de/ext/e2e-coref/data/tuebadz-9.1-conll2011.txt\", 'r') as outfile:\n",
    "    lines = outfile.readlines()\n",
    "    i = 0\n",
    "    same_sentence = False\n",
    "    for line in lines:\n",
    "        li=line.strip()\n",
    "\n",
    "        if not li.startswith(\"#\"): \n",
    "            if li:\n",
    "                if not same_sentence:\n",
    "                    _ = line.split()\n",
    "                    vector_dict[_[0]].append(lm_file[str(i)])\n",
    "                    same_sentence = True\n",
    "            else:\n",
    "                same_sentence = False\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for key in vector_dict:\n",
    "    for line in vector_dict[key]:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "hf = h5py.File('elmo.h5', 'w')\n",
    "for key in vector_dict:\n",
    "    try:\n",
    "        _group = hf.create_group(key)\n",
    "        [_group.create_dataset(key + \".\" + str(i), data=np.array(sentence)) for i, sentence in enumerate(vector_dict[key])]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        hf.close()\n",
    "        break\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_h5_file = h5py.File(\"elmo.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T990507.2\n",
      "<HDF5 group \"/T990507.2\" (35 members)>\n",
      "<HDF5 dataset \"T990507.2.0\": shape (3, 5, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.1\": shape (3, 17, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.10\": shape (3, 10, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.11\": shape (3, 8, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.12\": shape (3, 22, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.13\": shape (3, 18, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.14\": shape (3, 26, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.15\": shape (3, 21, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.16\": shape (3, 19, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.17\": shape (3, 25, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.18\": shape (3, 19, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.19\": shape (3, 16, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.2\": shape (3, 6, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.20\": shape (3, 32, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.21\": shape (3, 14, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.22\": shape (3, 28, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.23\": shape (3, 20, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.24\": shape (3, 19, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.25\": shape (3, 17, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.26\": shape (3, 21, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.27\": shape (3, 16, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.28\": shape (3, 22, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.29\": shape (3, 19, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.3\": shape (3, 26, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.30\": shape (3, 13, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.31\": shape (3, 14, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.32\": shape (3, 30, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.33\": shape (3, 14, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.34\": shape (3, 2, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.4\": shape (3, 15, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.5\": shape (3, 39, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.6\": shape (3, 40, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.7\": shape (3, 12, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.8\": shape (3, 26, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"T990507.2.9\": shape (3, 24, 1024), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "for key in created_h5_file:\n",
    "    print(key)\n",
    "    print(created_h5_file[key])\n",
    "    for sen in created_h5_file[key]:\n",
    "        print(created_h5_file[key][sen])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print(lm_file[\"T890612.87.20\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "keys = []\n",
    "for key in lm_file:\n",
    "    keys.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "nopes = []\n",
    "keys.sort(key=natural_keys)\n",
    "for i, key in enumerate(keys):\n",
    "    doc_id = key[:key.rindex(\".\")]\n",
    "    sent_id = int(key[key.rindex(\".\")+1:])\n",
    "    if i == 0:\n",
    "        if not sent_id == i + 1:\n",
    "            nopes.append((doc_id, sent_id -1))\n",
    "        _tmp_doc = doc_id\n",
    "        _tmp_sent = sent_id\n",
    "    elif sent_id != 1 and not doc_id == _tmp_doc:\n",
    "        print(doc_id, sent_id, _tmp_doc)\n",
    "        nopes.append((doc_id, sent_id -1))\n",
    "    else:\n",
    "        if doc_id == _tmp_doc and not _tmp_sent == sent_id - 1:\n",
    "            nopes.append((doc_id, sent_id -1))\n",
    "        _tmp_sent = sent_id\n",
    "        _tmp_doc = doc_id\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "for key in lm_file:\n",
    "    keys.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 102399\n"
     ]
    }
   ],
   "source": [
    "print(len(nopes), len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('T890102.84', 3), ('T890103.246', 54), ('T890104.37', 3), ('T890107.209', 24), ('T890118.155', 15), ('T890130.95', 1), ('T890130.95', 2), ('T890130.95', 3), ('T890130.95', 4), ('T890130.95', 5), ('T890130.95', 6), ('T890130.95', 7), ('T890130.95', 8), ('T890130.95', 9), ('T890130.95', 10), ('T890130.95', 11), ('T890130.95', 12), ('T890130.95', 13), ('T890130.95', 14), ('T890130.95', 15), ('T890130.95', 16), ('T890130.95', 17), ('T890130.95', 18), ('T890130.95', 19), ('T890130.95', 20), ('T890130.95', 21), ('T890130.95', 22), ('T890130.95', 23), ('T890130.95', 24), ('T890130.95', 25)]\n"
     ]
    }
   ],
   "source": [
    "print(nopes[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open('wrong_news.txt', 'a')\n",
    "for nope in nopes:\n",
    "    file_object.write(nope[0] + \" \")\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
